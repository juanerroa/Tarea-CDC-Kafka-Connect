
# üìñ Change Data Capture con SQL Server ‚Üí Kafka ‚Üí PostgreSQL

![Sample](sample.gif)

## üéØ Introducci√≥n y Prop√≥sito

Este proyecto demuestra c√≥mo replicar cambios en tiempo real desde una base de datos **SQL Server** hacia **PostgreSQL** utilizando **Apache Kafka** y **Kafka Connect**.

El caso de uso principal es la replicaci√≥n de datos transaccionales, como una tabla de clientes de un sistema bancario, hacia un destino anal√≠tico o un data warehouse para su posterior procesamiento sin afectar la base de datos de producci√≥n.

### Beneficios del Enfoque

  * ‚ö° **Captura de Cambios en Tiempo Real:** Los datos se replican con baja latencia a medida que se producen.
  * üõ† **Escalabilidad y Desacoplamiento:** Los sistemas de origen y destino no est√°n directamente acoplados, lo que permite un mantenimiento y escalado independientes.
  * üîå **F√°cil Integraci√≥n:** Kafka act√∫a como un bus central de eventos, facilitando la conexi√≥n de m√∫ltiples sistemas adicionales (consumidores o productores) en el futuro.

-----

## üìÅ Estructura del Proyecto

El repositorio est√° organizado de la siguiente manera para facilitar el despliegue y la configuraci√≥n:

```
CDC-Project/
‚îú‚îÄ docker-compose.yml        # Define y orquesta todos los servicios en contenedores.
‚îú‚îÄ db.init/                  # Guarda las tablas necesarias a crear en las bases de datos
‚îÇ  ‚îú‚îÄ sqlserver.sql          # Tablas de SQL a crear para usar como fuente de datos par ala demostraci√≥n
‚îú‚îÄ connectors/
‚îÇ  ‚îú‚îÄ sqlserver-source.json  # Configuraci√≥n del conector de origen (SQL Server).
‚îÇ  ‚îî‚îÄ postgres-sink.json     # Configuraci√≥n del conector de destino (PostgreSQL).
‚îú‚îÄ init-connectors.bash      # Script para registrar los conectores en la API de Kafka Connect.
‚îú‚îÄ postman_collection.json   # Colecci√≥n de postman para gestionar los conectores (opcionalmente si no se usa Curl)
‚îî‚îÄ README.md                 # Doc
```

Se incluye un archivo `.gitignore` para excluir archivos innecesarios y sensibles del control de versiones, tales como:

  * Datos de vol√∫menes de Docker.
  * Logs generados por las aplicaciones.
  * Archivos temporales del sistema.
  * Configuraciones locales del IDE.
  * Archivos de credenciales como `.env`.

-----

## üèõÔ∏è Arquitectura T√©cnica Detallada

### Componentes del Sistema

  * üñ• **SQL Server 2022:** Base de datos relacional que act√∫a como la fuente de datos transaccionales.
  * ‚ö° **Apache Kafka:** Plataforma de streaming de eventos que funciona como bus de mensajes.
  * üîó **Kafka Connect:** Framework para conectar Kafka con sistemas externos de forma fiable y escalable.
  * üêò **PostgreSQL:** Base de datos relacional de c√≥digo abierto que act√∫a como destino de los datos.

### Flujo de Datos Paso a Paso

El flujo de datos sigue una secuencia l√≥gica y desacoplada a trav√©s de los componentes:

```
1. SQL Server (Tabla 'Clients')
        ‚îÇ
        ‚ñº
2. Kafka Connect Source Connector (JDBC)
        ‚îÇ (Lee cambios basados en una columna incremental)
        ‚ñº
3. Kafka Topic: 'SQLServer_Clients'
        ‚îÇ (Los cambios se publican como mensajes)
        ‚ñº
4. Kafka Connect Sink Connector (JDBC)
        ‚îÇ (Consume mensajes del topic)
        ‚ñº
5. PostgreSQL (Tabla 'clients_new')
```

-----

## ‚öôÔ∏è Requisitos del Sistema

### Software

  * **Docker y Docker Compose:** Versi√≥n `3.9` o superior.
  * **Puertos Disponibles:**
      * `1433` ‚Üí SQL Server
      * `5432` ‚Üí PostgreSQL
      * `9092` ‚Üí Kafka Broker
      * `8083` ‚Üí Kafka Connect REST API

### Hardware (M√≠nimo)

  * **RAM:** 4GB
  * **CPU:** 2 n√∫cleos

-----

## üöÄ Despliegue

Para levantar toda la infraestructura.

1.  **Levantar todos los servicios con Docker Compose:**

    ```bash
    docker compose up -d
    ```

2.  **Verificar que todos los contenedores est√©n activos:**

    ```bash
    docker ps
    ```

3.  **Revisar los logs de Kafka Connect** para asegurar que se ha iniciado correctamente:

    ```bash
    docker logs -f tarea-1-kafka-connect-1
    ```

    *Busca un mensaje que indique que la API REST est√° escuchando en el puerto `8083`.*

-----

## üìã Configuraci√≥n de Conectores

Los conectores se definen en archivos JSON y se registran a trav√©s de la API REST de Kafka Connect.

### Source Connector ‚Äì SQL Server

Este conector lee la tabla `Clients` en modo incremental usando la columna `ClientId`.

`connectors/sqlserver-source.json`

```json
{
  "name": "sqlserver-source", // Nombre del conector
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector", // Tipo de conector: JDBC Source
    "tasks.max": "1", // N√∫mero m√°ximo de tareas concurrentes
    "connection.url": "jdbc:sqlserver://sqlserver:1433;databaseName=BankingCore", // URL de conexi√≥n a SQL Server
    "connection.user": "sa", // Usuario de SQL Server
    "connection.password": "DummyPass123!", // Contrase√±a de SQL Server
    "mode": "incrementing", // Tipo de captura: incremental
    "incrementing.column.name": "ClientId", // Columna que se usa para detectar nuevas filas
    "table.whitelist": "Clients", // Tabla a monitorear
    "topic.prefix": "SQLServer_", // Prefijo para los topics generados en Kafka
    "poll.interval.ms": 5000 // Intervalo de polling en milisegundos
  }
}
```


`connectors/postgres-sink.json`

```json
{
  "name": "postgres-sink", // Nombre del conector
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector", // Tipo de conector: JDBC Sink
    "tasks.max": "1", // N√∫mero m√°ximo de tareas concurrentes
    "connection.url": "jdbc:postgresql://postgres-sink:5432/postgres", // URL de conexi√≥n a PostgreSQL
    "connection.user": "sa", // Usuario de PostgreSQL
    "connection.password": "DummyPass123!", // Contrase√±a de PostgreSQL
    "auto.create": "true", // Crea la tabla autom√°ticamente si no existe
    "auto.evolve": "true", // Actualiza la tabla si cambian columnas
    "delete.enabled": "false", // No eliminar filas en el destino
    "topics": "SQLServer_Clients", // Topic de Kafka a consumir
    "table.name.format": "clients_new" // Nombre de la tabla destino
  }
}
```



```bash
./init-connectors.bash
```

-----

## üß™ Pruebas de Integraci√≥n

Para validar que el pipeline funciona de extremo a extremo:

1.  **Insertar datos de prueba en SQL Server:**
    Se puede usar un cliente SQL o ejecutar el siguiente comando a trav√©s de Docker:

    ```sql
    INSERT INTO Clients (FirstName, LastName, Email) VALUES ('Juan', 'Perez', 'juan.perez@example.com');
    ```

2.  **Verificar que los datos llegaron a PostgreSQL:**
    Con√©ctarse a la base de datos de PostgreSQL y ejecuta una consulta:

    ```sql
    SELECT * FROM clients_new;
    ```

    *Se deberia ver el registro de 'Juan Perez' despu√©s de unos segundos (seg√∫n el `poll.interval.ms`).*

-----

## üîç Verificaci√≥n y Monitoreo

Usar la API REST de Kafka Connect para verificar el estado de los conectores:

```bash
# Listar todos los conectores activos
curl http://localhost:8083/connectors

# Verificar el estado del conector de origen
curl http://localhost:8083/connectors/sqlserver-source/status

# Verificar el estado del conector de destino
curl http://localhost:8083/connectors/postgres-sink/status
```

Para depuraci√≥n, los logs del contenedor de Kafka Connect la principal fuente de informaci√≥n:

```bash
docker logs -f tarea-1-kafka-connect-1
```

-----

## üîß Problemas Comunes

  * **`InvalidReplicationFactorException`:** Ocurre si solo tienes un broker de Kafka. Aseg√∫rate de que las variables de entorno para los topics internos de Connect (`CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR`, etc.) est√©n configuradas en `1`.
  * **Puerto REST no accesible:** Revisa la variable `CONNECT_REST_ADVERTISED_HOST_NAME` en tu `docker-compose.yml` para asegurarte de que es accesible desde tu host.
  * **Datos no replicados:** Verifica que la columna `incrementing.column.name` existe y sus valores aumentan. Revisa tambi√©n el `poll.interval.ms` por si la latencia es mayor de la esperada.

-----

## ‚ö° Optimizaci√≥n y Buenas Pr√°cticas

  * **Memoria de Kafka Connect:** Se debe ajustar la memoria de la JVM para Kafka Connect usando la variable de entorno `HEAP_OPTS` para manejar cargas de trabajo m√°s grandes.
  * **Ajustar del `poll.interval.ms`:** Un intervalo m√°s bajo reduce la latencia pero aumenta la carga en la base de datos de origen. Aj√∫stalo seg√∫n tus necesidades.
  * **Monitoreo:** Implementar herramientas de monitoreo para supervisar el rendimiento (throughput, latencia) y configurar alertas para logs de errores.
